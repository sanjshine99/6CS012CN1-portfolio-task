{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbBjDeHE9zH8/WTqPqLbx5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NEektS_9w0LF","executionInfo":{"status":"ok","timestamp":1704025490449,"user_tz":-330,"elapsed":732,"user":{"displayName":"Sanjana Bandara","userId":"00355962272634621592"}},"outputId":"e5e160d4-9925-4f4a-d9a4-7dfc2ab019f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["test input shape:  (30, 4) test output shape:  (30,)\n","train input shape:  (120, 4) train output shape:  (120,)\n","Cross-entropy loss after: 10 iterations: 1.0486170566460653\n","Cross-entropy loss after: 100 iterations: 1.0324314913767128\n","Cross-entropy loss after: 1000 iterations: 0.5950138392122908\n","Cross-entropy loss after: 10000 iterations: 0.31618791255362805\n","[[1.47779737e-01 2.17860614e-02 6.43482016e-05]\n"," [4.42382670e-02 3.41319105e-02 1.39754155e-04]\n"," [1.27412194e-01 2.15301684e-02 7.79028776e-05]\n"," [6.81700835e-02 2.18118612e-02 1.63396197e-04]\n"," [6.14626270e-02 2.15770799e-02 1.85567714e-04]]\n","\n"," Testing Accuracy after 10000 iterations:\n"," 100.0\n","Class-1 Accuracy:  100.0 \n","Class-1 Accuracy:  100.0 \n","Class-1 Accuracy:  100.0\n"]}],"source":["# Step 1: Import Libraries\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import normalize\n","import scipy.sparse\n","from sklearn import datasets\n","from sklearn.linear_model import LogisticRegression\n","\n","# Step 2: Read data as array\n","iris = datasets.load_iris()\n","list(iris.keys())\n","X = iris[\"data\"] # petal width\n","\n","# Step 3: Normalize Data\n","X = normalize(X, norm='l2')\n","\n","# Step 4: Split data into target and input\n","y = iris[\"target\"]\n","m = y.shape[0]\n","\n","# Step 5: Train Test Split\n","# Test Split\n","X_test = np.concatenate([X[40:50,:], X[90:100,:], X[140:150,:]])\n","y_test = np.concatenate([y[40:50], y[90:100], y[140:150]])\n","print(\"test input shape: \",X_test.shape,\"test output shape: \", y_test.shape)\n","# Train Split\n","X = np.concatenate([X[0:40,:], X[50:90,:], X[100:140,:]])\n","y = np.concatenate([y[0:40], y[50:90], y[100:140]])\n","print(\"train input shape: \", X.shape,\"train output shape: \", y.shape)\n","\n","# Step 6: One-Hot Encoding\n","def oneHotIt(Y):\n","    m = Y.shape[0]\n","    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n","    OHX = np.array(OHX.todense()).T\n","    return OHX\n","y_mat = oneHotIt(y)  # Next we convert the integer class coding into a one-hot representation\n","yo=y_mat\n","\n","# Step 7: Define number of iterations, learning rate, and iniital theta\n","\n","iterations = [10, 100, 1000, 10000]\n","\n","eta = 0.1 # learning rate\n","m = y.shape[0]\n","for n_iterations in iterations:\n","    theta = np.random.rand(4,3)  # reset theta for each iteration\n","    for iteration in range(n_iterations):\n","        logits = X.dot(theta)\n","        y_proba = softmax(logits, axis=1)\n","        error = y_proba - y_mat  # Use y_mat instead of y\n","        gradients = 1/m * X.T.dot(error)\n","        theta = theta - eta * gradients\n","    # Compute the cross-entropy loss\n","    logits = X.dot(theta)\n","    y_proba = softmax(logits, axis=1)\n","    cross_entropy = -np.mean(np.sum(y_mat * np.log(y_proba + 1e-7), axis=1))  # Use y_mat instead of y\n","    print(\"Cross-entropy loss after:\", n_iterations, \"iterations:\", cross_entropy)\n","\n","# Step 11: Test Accuracy (Combined)\n","\n","from scipy.special import softmax\n","theta_best = theta\n","y_test_soft = X_test.dot(theta_best)\n","y_test_soft = softmax(y_test_soft, axis =0)\n","print(y_test_soft[:5,:])\n","\n","\n","y_test_soft = np.argmax(y_test_soft, axis = 1)\n","\n","accuracy = np.sum(y_test == y_test_soft) / (float(len(y_test_soft)))\n","\n","print(\"\\n Testing Accuracy after\",n_iterations,\"iterations:\\n\", accuracy*100)\n","\n","# Test Accuracy (class-wise)\n","\n","cm = y_test == y_test_soft\n","\n","c1 = np.sum(cm[:10])/float(10)\n","c2 = np.sum(cm[10:20])/float(10)\n","c3 = np.sum(cm[20:])/float(10)\n","print(\"Class-1 Accuracy: \", c1*100,\"\\nClass-1 Accuracy: \", c2*100,\"\\nClass-1 Accuracy: \", c3*100)"]}]}